1. Importando bibliotecas
```
import tensorflow as tf
import tensorflow_datasets as tfds
import matplotlib.pyplot as plt
```

ğŸ“ ExplicaÃ§Ãµes:
- tensorflow: biblioteca principal usada para construir e treinar redes neurais.
- tensorflow_datasets (tfds): ferramenta da prÃ³pria equipe do TensorFlow que facilita o acesso a bases de dados famosas.
- matplotlib.pyplot: biblioteca usada para visualizar grÃ¡ficos, como curvas de acurÃ¡cia.

2. Carregando o dataset Caltech101
```
(ds_train, ds_test), ds_info = tfds.load(
    'caltech101',
    split=['train[:80%]', 'train[80%:]'],
    shuffle_files=True,
    as_supervised=True,
    with_info=True
)
```

ğŸ“ ExplicaÃ§Ãµes:
- tfds.load: baixa e prepara o dataset automaticamente.
- 'caltech101': nome do dataset a ser carregado.
- split: separa o conjunto em 80% para treino, 20% para teste.
- shuffle_files=True: embaralha os arquivos para nÃ£o ter viÃ©s na ordem.
- as_supervised=True: retorna tuplas (imagem, rÃ³tulo) ao invÃ©s de dicionÃ¡rios.
- with_info=True: retorna metadados do dataset (como o nome das classes).

3. Verificando os nomes das classes
```
print(ds_info.features['label'].names)
```

ğŸ“ ExplicaÃ§Ãµes:
- Mostra uma lista com os nomes das 101 classes (ex: 'camera', 'airplanes', etc.).

4. Selecionando duas classes especÃ­ficas
```
selected_classes = ['camera', 'motorbikes']
class_names = ds_info.features['label'].names
selected_ids = [class_names.index(name) for name in selected_classes]
```

ğŸ“ ExplicaÃ§Ãµes:
- selected_classes: vocÃª define manualmente as duas classes que deseja usar.
- class_names: lista com o nome de todas as classes do dataset.
- selected_ids: obtÃ©m os Ã­ndices numÃ©ricos correspondentes aos nomes selecionados (necessÃ¡rio para filtrar depois).

5. Filtrando apenas essas duas classes
```
def filter_classes(image, label):
    return tf.reduce_any([label == selected_ids[0], label == selected_ids[1]])
```

ğŸ“ ExplicaÃ§Ãµes:
- FunÃ§Ã£o que serÃ¡ usada para filtrar apenas imagens cujos rÃ³tulos pertenÃ§am Ã s duas classes escolhidas.
- tf.reduce_any(...): retorna True se qualquer condiÃ§Ã£o for verdadeira.

6. Reconvertendo rÃ³tulos para 0 e 1
```
def reencode_labels(image, label):
    new_label = tf.cast(label == selected_ids[1], tf.int64)
    return image, new_label
```

ğŸ“ ExplicaÃ§Ãµes:
- Convertemos os rÃ³tulos para 0 ou 1 para facilitar o uso de classificaÃ§Ã£o binÃ¡ria.
- Se o rÃ³tulo for igual Ã  segunda classe (ex: 'motorbikes'), ele vira 1; senÃ£o, 0.

7. PrÃ©-processamento de imagens
```
IMG_SIZE = (160, 160)
BATCH_SIZE = 32

def preprocess(image, label):
    image = tf.image.resize(image, IMG_SIZE) / 255.0
    return image, label
```

ğŸ“ ExplicaÃ§Ãµes:
- IMG_SIZE: define que todas as imagens terÃ£o tamanho 160x160 pixels.
- BATCH_SIZE: nÃºmero de imagens processadas por vez durante o treino.
- preprocess: redimensiona cada imagem e normaliza os pixels (de 0 a 1).

8. Aplicando filtros e criando os datasets finais
```
train_ds = ds_train.filter(filter_classes).map(reencode_labels).map(preprocess).batch(BATCH_SIZE).prefetch(1)
test_ds = ds_test.filter(filter_classes).map(reencode_labels).map(preprocess).batch(BATCH_SIZE).prefetch(1)
```

ğŸ“ ExplicaÃ§Ãµes:
- .filter(...): aplica a funÃ§Ã£o de filtro para manter sÃ³ as duas classes.
- .map(...): aplica a conversÃ£o de rÃ³tulos e depois o prÃ©-processamento.
- .batch(BATCH_SIZE): agrupa imagens em lotes de 32.
- .prefetch(1): melhora o desempenho carregando os dados enquanto o modelo treina.

9. Carregando o modelo prÃ©-treinado MobileNetV2
```
base_model = tf.keras.applications.MobileNetV2(
    input_shape=IMG_SIZE + (3,),
    include_top=False,
    weights='imagenet'
)
base_model.trainable = False
```

ğŸ“ ExplicaÃ§Ãµes:
- MobileNetV2: rede treinada com milhÃµes de imagens (ImageNet).
- input_shape: precisa combinar com o tamanho das nossas imagens (160x160x3).
- include_top=False: remove a â€œcabeÃ§aâ€ original do modelo (classificador original).
- weights='imagenet': carrega os pesos jÃ¡ treinados.
- trainable=False: congela os pesos para usar como extrator de caracterÃ­sticas fixo.

10. Adicionando novas camadas para nosso problema
```
model = tf.keras.Sequential([
    base_model,
    tf.keras.layers.GlobalAveragePooling2D(),
    tf.keras.layers.Dense(1, activation='sigmoid')
])
```

ğŸ“ ExplicaÃ§Ãµes:
- Sequential: cria uma pilha de camadas.
- GlobalAveragePooling2D: resume cada mapa de ativaÃ§Ã£o com uma mÃ©dia (reduz parÃ¢metros).
- Dense(1, activation='sigmoid'): camada final com 1 saÃ­da para classificaÃ§Ã£o binÃ¡ria.

11. Compilando o modelo
```
model.compile(optimizer='adam',
              loss='binary_crossentropy',
              metrics=['accuracy'])
```

ğŸ“ ExplicaÃ§Ãµes:
- optimizer='adam': algoritmo eficiente para ajuste dos pesos.
- loss='binary_crossentropy': funÃ§Ã£o de perda usada em classificaÃ§Ãµes binÃ¡rias.
- metrics=['accuracy']: acompanha a acurÃ¡cia durante o treinamento.

12. Treinando o modelo
```
history = model.fit(
    train_ds,
    validation_data=test_ds,
    epochs=5
)
```

ğŸ“ ExplicaÃ§Ãµes:
- model.fit(...): treina o modelo.
- epochs=5: faz 5 passagens completas pelos dados.
- validation_data: validaÃ§Ã£o com dados que o modelo nunca viu.

13. Visualizando a acurÃ¡cia
```
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']

plt.plot(acc, label='Treinamento')
plt.plot(val_acc, label='ValidaÃ§Ã£o')
plt.legend()
plt.title("AcurÃ¡cia por Ã‰poca")
plt.show()
```

ğŸ“ ExplicaÃ§Ãµes:
- history.history: contÃ©m os registros da acurÃ¡cia a cada Ã©poca.
- plt.plot: desenha os grÃ¡ficos para comparar treino vs. validaÃ§Ã£o.
- Isso ajuda a ver se o modelo estÃ¡ aprendendo ou sofrendo overfitting.